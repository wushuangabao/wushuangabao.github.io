# 【学习】许世伟的架构课（极客时间）
```
tags:
  - 学习
  - 软件
categories:
  - 软件工程

date: 2019-06-17 22:27:03
```

## 开篇词 | 怎样成长为优秀的软件架构师？

许世伟2000年开始工作，曾是WPS首席架构师，在盛大做过，2011年创立了七牛云，现在是一名创业者、CEO。


把程序员类比成建筑师，按能力来分有三个层次：**搬砖师、工程师、架构师**。

软件诞生后，需要花费大量代价维护。程序员更多的时间是用来维护代码。

**代码质量的评判有这样一些基本维度：可阅读性、可扩展性/可维护性、可测试性、可复用性**。

阅读和维护软件工程师写的代码会有一种赏心悦目的感觉。

软件工程是一项非常复杂的系统工程，它需要依赖一个能**掌控全局**的团队，来规划和引导整个系统的演变过程。这个团队就是架构师团队。

掌控全局的前提是：在自己心中去重新构筑出整个世界。

**课程脉络**：首先，我们通过还原信息世界的构建过程，剥离出了整个信息世界的核心骨架，这也是最真实、最宏大的架构实践案例。其次，我们结合这个宏大的架构实践来谈架构思维，避免因对架构思维的阐述过于理论化而让人难以理解。

## 01架构设计的宏观视角

课程内容从基础架构讲起，慢慢过渡到业务架构。

### 应用程序的基础架构

电脑的构成：中央处理器+存储+一系列的输入输出设备

如此简单，电脑却能完成复杂和多样化的功能。主要依赖两点：

1. 可编程性。虽然CPU指令是一个有限的指令集，但是CPI执行的指令序列并不固定，而是依赖存储中的数据（程序）来决定。
2. 开放设计的外部设备支持。CPU并不理解外部设备具有什么样的能力，只和它们交换数据。

CPU是一个非常简洁的模型，它只读写数据，对数据进行计算。

- 机器指令编写软件太累——编程语言+编译器出现
- 多个软件写数据、传指令冲突怎么办——操作系统出现，解决软件治理和基础编程接口问题

### 完整的程序架构是怎么样的？

业务架构（应用架构），只须关心应用程序的本身的**业务问题如何构建**。

不同的业务架构之间，不止遵循相同的**架构原则**，还可以遵循相同的的**设计范式**。例如，在用户交互领域有著名的 MVC 框架（如 JavaScript 语言的 Angular，PHP 语言的 Zend，Python 语言的 Django），在游戏开发领域有各种游戏引擎（如 JavaScript 语言的 Phaser，C# 语言的 Unity3D），等等。

对于一个服务端应用程序来说，其完整的架构体系大体如下图：

![服务端架构图](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/0MSWJ4nCfsEX6w4ta.FIUFxYPeQReg5sC5dQlRDsh5s!/b/dL4AAAAAAAAA&bo=GwU.AwAAAAARBxM!&rf=viewer_4)

客户端应用程序和服务端有很大差别，首先面临多样性的挑战（操作系统、设备种类）。

浏览器是第一个想要消除客户端的多样性，跨平台提供统一接口的，地位非常特殊，可以看做是操作系统之上的操作系统。对于一个客户端应用程序来说，其完整的架构体系大体如下：

![客户端架构图](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/.wKTGDkr5hAa2IZp6DWpX2.KhtlK0XMdLmF8mHE2ovE!/b/dMAAAAAAAAAA&bo=vQV2AwAAAAARB*0!&rf=viewer_4)

## 02解剖冯·诺依曼体系结构

### 解剖架构的关键点

当我们设计或分析架构设计中涉及的每一个零部件时，我们关心哪些问题？

1. 需求。这个零部件的作用是什么？它被用来做哪些事？不会被用来做哪些事？为什么不会？
2. 规格。这个零部件的接口是什么样的？它如何与其他零件连接在一起？

**解决一切可“计算”问题，这是冯·诺依曼的需求**。

### 冯·诺依曼体系的规格

为了实现需求，冯·诺依曼引入了三类基础零部件：
- 中央处理器，负责程序（指令序列）的执行；
- 存储（中央处理器内置支持的存储）；
- 输入输出设备。

**为什么这么简洁的规格设计，可以解决这么复杂的需求**？

### 需求是怎么被满足的？

一方面，**需求的变化点**在于，要解决的问题是五花八门包罗万象的。如何以某种稳定但可扩展的架构来支持这样的变化？而另一方面，**需求的稳定之处**在于，电脑的核心能力是固定的。

电脑的核心能力是“计算”。就是对一个数据（输入）进行变换，变为另一个数据（输出）。在数学中我们把它叫做“函数”。

> y = F(x)

这里x、y是数据。无论它们的逻辑含义为何，物理上都可以用一段连续的字节内容来表达。那么x、y物理上在哪里？得有一个“存储”用来存放操作的数据。

而函数 F，对于架构师来说也是未知的。怎样设计一种架构让用户可以表达任意复杂度的函数（计算）？逻辑上，无论多复杂的自定义函数，都可以用一组指令序列来表达。这些指令包括：
- 执行最小计算单元，如数字的加减乘除（也就是内置函数）；
- 执行顺序，包括条件分支、循环；
- 执行其他自定义的函数（子函数）。

F 物理上在哪里？以指令序列（程序）形式存放在存储里。**存储不仅存放数据，也存放“计算”本身**。

有了负责计算的中央处理器，以及存储，就可以进行任意复杂的“计算”了。但是它无法和现实世界发生交互，即输入和输出。

对于电脑来说，输入输出的需求就更多了。但不管是什么样交互用途的设备，我们要做的只是**定义好统一的数据交换协议**。

除了纯正的“计算”能力外，中央处理器还要有“数据交换”能力（或者叫 IO 能力）。

最终，电脑可以被看做由 “**中央处理器 + 存储 + 一系列的输入输出设备**” 构成。

（以上内容仅仅是说明，具体细节参考学科：计算机组成原理、汇编语言等）

### 架构思维总结

架构的第一步是需求分析。需求分析的关键是**抓住需求的稳定点和变化点**。架构目标是剥离变化的部分，将其抽象到接口层去实现（做成开放性设计），让系统的核心价值（功能）保持稳定。

对于“电脑”这个产品而言，需求的稳定点是电脑的“计算”能力。需求的变化点，一是用户“计算”需求的多样性，二是用户交互方式的多样性。

电脑的“计算”能力，最终体现为中央处理器的指令集，这是需求相对稳定的部分。

用户“计算”需求的多样性，最终是通过在存储中的指令序列实现。计算机加电启动后，中央处理器并不是按自己固有的“计算”过程进行，而是从一个固定的存储地址加载指令序列执行。

扩展阅读：
- [电脑结构和CPU、内存、硬盘三者之间的关系](https://www.cnblogs.com/resn/p/5766142.html)
- [计算机发展史](https://www.cnblogs.com/resn/p/5731067.html)

## 03汇编语言的诞生

对于现代计算机来说，虽然 CPU 指令是一个很有限的指令集，但是 CPU 执行的指令序列（或者叫“程序”）并不是固定的，它依赖于保存在存储中的数据，由软件工程师（或者叫“程序员”）编写的软件决定。

在第一门面向程序员的编程语言出现前，人们只能通过理解 CPU 指令的二进制表示，将程序以二进制数据方式刻录到存储（比如 ROM 或硬盘）上。

这个时候软件和硬件的边界还非常模糊，并不存在所谓软件工程师（或者叫“程序员”）这样的职业。写程序也并不是一个纯软件的行为，把程序刻录到存储上往往还涉及了硬件的电气操作。

为了解决编程效率的问题，汇编语言（和解释它的编译器）诞生了。汇编语言的编译器将汇编语言写的程序编译成为 CPU 指令序列，并将其保存到外置的存储设备（比如硬盘）上。

汇编语言的出现，让写程序（编程）成为一个纯软件行为（出现“程序员”这个分工的标志），人们可以专注于程序逻辑的表达、反复修改程序，然后通过汇编编译器将其翻译成机器语言，并写入到外置的存储设备（比如硬盘）。

这一步所解放的生产力是惊人的。程序的源代码可以进行**迭代演进**了。软件程序不断被传承，并最终演进出今天的信息世界。

## 04编程语言的进化

软件是活的书籍，是人类知识传承能力的一次伟大进化。它比书籍更好：
- 表达方式多样
- 对技术的现场还原

### 编程范式的进化

- 过程式。最核心的概念是结构体（自定义的类型）和过程（也叫函数）。
- 函数式。本质上是过程式编程的一种约束，核心主张是变量不可变、函数尽可能没有副作用。学习成本高，代表语言有 Haskell, Erlang。
- 面向对象。在过程式的基础上，主张尽可能把方法（即过程）归纳到合适的对象中。

面向对象的核心思想是引入契约，基于对象这个概念对代码的使用界面进行抽象和封装。有两个显著优点：
- 清晰的使用界面。数据结构和过程的关系不再松散。
- 信息的**封装**。提高了可复用性，通过接口优雅地实现**多态**的能力。

对于**继承**，褒贬不一。本来复合对象的唯一构造方法是组合，现在多了一个选择，令人纠结。

Go 语言给出了答案：放弃继承，全面强化**组合**能力。

一些语言明确主张自己是多范式的，比如 C++。

Go 保留了每一种编程范式的精华部分，但是 Go 官方认为 Go 是一门**面向连接**的语言。体现了朴素的组合思想。

Go 语言设计的方方面面都需要契约，直接消灭了那些代码写法容易产生区别的地方，让大家专注于意图的表达。

### 其他方面的进化

除了编程范式，编程语言的工程能力也越来越完善，体现在：
- 包（package），即代码的发布单元。
- 版本（version），即包的依赖管理。
- 文档生成（doc）。
- 单元测试（test）。

从语言的执行器行为看，出现了这样三种分类的语言：
- 编译的目标文件为可执行程序。典型代表有 Fortran, C/C++, Go 等。
- 生成跨平台的虚拟机字节码，有独立的执行器（虚拟机）执行字节码。典型代表 Java, Erlang。
- 直接解释执行。典型代表是 JavaScript。当然现在纯解释执行的语言已经不多了，大多数直接执行的语言内部还是会有虚拟机的。

### 语言对架构的影响

之前的架构图中，三种不同的颜色表示不同层次的依赖。

无论是服务端还是客户端，可以同意将其架构图简化为：
- 业务架构——源代码层次的依赖，程序本身的组成部分
- 应用程序框架及各类基础库——库层次的依赖，程序本身的组成部分，但与业务无关
- 基础软件（操作系统、编程语言及各种中间件）——软件层次的依赖，程序工作的生态环境
- 冯·诺依曼体系架构——硬件层次的依赖，程序工作的物理基础

从软件的业务架构来说，怎么拆分模块（确定业务边界）是业务需求本身决定的，与编程语言无关。但是在**描述每个模块的规格**时，采用的规格描述语言会面临如下两种选择：
- 选择某种语言无关的接口表示；
- 选择团队开发时采用的编程语言来描述接口。

两者无本质差异，但语言的选择在实践中对业务架构的决策的影响仍然及其关键。原因：
- 开发效率有差异。抛开语言本身的开发效率不谈，不同语言会有不同的社区资源，还有企业发展形成的框架和基础库；
- 后期维护。语言有生命周期，会走向衰弱。

## 06操作系统进场

操作系统就是软件之间的协调方，制定规则并约束这些软件的行为。

操作系统的执行权，是计算机主板 ROM 上的启动程序（BIOS）交给它的。

### 操作系统的需求演进

编程语言出现后，软件生产效率得到了大幅度提升。软件越来越多，多个软件如何和谐共处？这就诞生了**软件治理**的需求：
- 多个软件如何同时运行（多任务的需求）？
- 多个软件如何共同使用计算机上的存储空间（内存管理、文件系统的需求）？
- 多个软件如何共同使用同一个外部设备（设备管理的需求）？
- 多个软件如何相互通讯，如何进行数据交换（进程间通讯、共享内存的需求）？
- 病毒、恶意软件如何治理（安全管理的需求）？

**客户价值维度**

首先要解决的是**软件治理**问题。大体分为以下6个子系统：进程管理、存储管理、输入设备管理、输出设备管理、网络管理、安全管理。

其次解决的是**基础编程接口**问题。这些编程接口一方面简化了软件开发，另一方面提供了多软件共同运行的环境，实现了软件治理。

**商业价值维度**

操作系统是**基础的刚需软件**，计算机离不开操作系统。

操作系统也是**核心的流量入口**。占领了操作系统，就占有了用户。

无论是本地操作系统 iOS 和 Android，还是 Web 操作系统（浏览器）如微信小程序，都**实现了“帐号 - 支付 - 应用市场”这样的商业闭环**。这类操作系统，我们不妨把它叫做现代操作系统。

### 操作系统的边界

架构的第一步是需求分析。在架构设计过程中，需求分析至少应该花费三分之一的精力。

当我们说要做一个操作系统的时候，我们的自己对这句话的理解也是非常模糊的。尤其当我们正准备做的事情是一个新生事物的时候。

架构也关乎用户需求，我们不止要知道用户当前的需求，还要预测需求未来可能的变化，预判什么会发生、而什么不一定会发生。

我是否能预料到，有一天支付（Pay）系统会成为操作系统的核心子系统？如果不能，那怎么才能做到？

操作系统的边界到底在哪里？

看清楚这样三个角色的关系：
- 硬件（个人计算机、手机或其他）
- 操作系统
- 浏览器

### 小结

从客户需求来说，操作系统的核心价值在于：
- 实现软件治理，让多个软件和谐共处；
- 提供基础的编程接口，降低软件开发难度。

从商业价值来说，操作系统是刚性需求，核心的流量入口，兵家必争之地。

我们把引入了“账号 - 支付 - 应用市场”商业闭环的税收模式的操作系统，称为现代操作系统。

通过对硬件、操作系统、浏览器三者的关系分析，有助于对需求发展做出预判。

## 07软件运行机制及内存管理

软件治理的一个重要部分，就是让多个软件可以共同使用计算机的资源，不至于出现争抢的场面。

CPU 可以直接访问的存储资源非常少，只有：寄存器、内存（RAM）、主板上的 ROM。

- 寄存器访问速度非常非常快，但是数量很少，大部分程序员不直接打交道。
- ROM 是非易失的、只读的，所以它非常适合存储计算机的启动程序（BIOS）。
- 所以，内存的地位非常特殊，它是唯一的 CPU 内置支持，且会和程序员直接打交道的基础资源。

### 计算机的运行全过程

从时序来说，计算机从开机到关机的完整“计算”过程如下：
![计算机的计算过程](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/4YzlMoaL8df.hRmXpLnZ.4.5m1kCVjo4dbE**DGpJJQ!/b/dBkBAAAAAAAA&bo=oAU4BAAAAAARB6k!&rf=viewer_4)

- 首先，BIOS 程序没有固化在 CPU 中，而是独立放到主板的 ROM 上，是因为不同历史时期的计算机输入输出设备很不一样（有键盘 + 鼠标 + 显示器的，有触摸屏的，也有纯语音交互的；外置存储则有软盘、硬盘、闪存），这些变化我们通过调整 BIOS 程序就可以应对，而不需要修改 CPU。
- 引导区引导程序，是程序从内置存储（ROM）转到外置存储的边界。它很短，BIOS 只需要把它加载到内存执行就可以。这样系统的控制权就转到外置存储了。引导区引导程序不固化在 BIOS 中，而是写在外置存储的引导区。毕竟 BIOS 还是硬件，而引导区引导程序已经属于软件范畴了，修改起来会方便很多。
- OS 引导程序，是外置存储接手计算机控制权的真正开始。操作系统从这里开始干活了。最终所有的初始化工作完成后，操作系统会把执行权交给 OS Shell 程序。
- OS Shell 程序负责操作系统与用户的交互。最早的时候，OS Shell 程序是一个命令行程序，DOS 中叫 command.com，而在 Linux 下则叫 sh 或者 bash 之类。这个时期启动一个软件的方式就是在 Shell 程序中输入一个命令行。到了图形界面时期，在 Shell 中启动软件就变成点点鼠标，或者动动手指。

关键细节：计算机是如何运行外置存储上的软件的？

通过内存管理。涉及两个问题：
- 如何分配内存；
- 如何运行外置存储上的软件。

CPU 对内存的操作方式有两个不同模式：
- 在实模式下，CPU 直接通过物理地址访问内存。
- 在保护模式下，CPU 通过一个地址映射表把虚拟的内存地址转为物理的内存地址，然后再去读取数据。

### 实模式下的内存管理

在实模式操作系统下，所有软件包括操作系统本身，都在同一个物理地址空间下。在 CPU 看来，它们是同一个程序。

**操作系统如何分配内存**？至少有两种可行的方法：
1. 把操作系统内存管理相关的函数地址，放到一个大家公认的地方（比如 0x10000 处），每个软件要想申请内存就到这个地方取得内存管理函数并调用它。
2. 把内存管理功能设计为一个中断请求。

> 所谓中断，是 CPU 响应硬件设备事件的一个机制。当某个输入输出设备发生了一件需要 CPU 来处理的事情，它就会触发一个中断。
> 内存的全局有一个中断向量表，本质上就是在一个大家公认的地方放了一堆函数地址。比如键盘按了一个键，它会触发 9 号中断。在 CPU 收到中断请求时，它会先停下手头的活来响应中断请求（到中断向量表找到第 9 项对应的函数地址并去执行它），完成后再回去干原来的活。
> 中断机制设计之初本来为响应硬件事件之用，但是 CPU 也提供了指令允许软件触发一个中断，我们把它叫软中断。比如我们约定 77 号中断为内存管理中断，操作系统在初始化时把自己的内存管理函数写到中断向量表的第 77 项。

上面两种方法实质上是同一个方法，只是机制细节有所不同而已。中断机制远不止是函数向量表那么简单。比如中断会有优先级，高优先级中断可以打断低优先级中断，反之则不能。

在实模式下，**操作系统如何运行外置存储（比如硬盘）上的软件**？

把软件完整从外置存储读入到内存然后执行它。不过在执行前，先把浮动地址固定下来。为什么会有浮动地址？因为软件还没有加载到内存的时候并不知道自己会在哪里，所以有很多涉及数据的地址、函数的地址都没法固定下来，要在操作系统把它加载到内存时来确定。

整体来说，实模式内存管理的机制是非常容易理解的。因为它毕竟实质上是一个程序被拆分为很多个软件（程序代码片段），实现了程序代码片段的动态加载而已。

**实模式的问题**：
1. 安全性。操作系统及所有软件都运行在一起，相互之间可以随意修改对方的数据甚至程序指令。
2. 支持的软件复杂性低，同可运行的软件数量少。

### 保护模式下的内存管理

保护模式下，内存访问不再是直接通过物理内存，而是基于虚拟内存。
虚拟内存模式下，整个内存空间被分成很多个连续的**内存页**。每个内存页大小是固定的，比如 64K。

这样，每次 CPU 访问某个虚拟内存地址中的数据，它都会先计算出这是要访问哪个内存页，然后 CPU 再通过一个地址映射表，把虚拟的内存地址转为物理的内存地址，然后到这个物理内存地址去读取数据。**地址映射表是一个数组，下标是内存页页号，值是该内存页对应的物理内存首地址。**

![地址映射表](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/Q.snlOQ69EGxuVmXFDQ4FhLbQTCzQuw50Guv2KDK4sQ!/b/dBMBAAAAAAAA&bo=gAfHAwAAAAARB3M!&rf=viewer_4)

> 有可能某一个内存页对应的物理内存地址不存在，这种情况叫**缺页**，没法读取数据，这时 CPU 就会发起一个缺页的中断请求。
> 这个缺页的中断请求会被操作系统接管。发生缺页时，操作系统会为这个内存页分配物理的内存，并恢复这个内存页的数据。如果没有空闲的物理内存可以分配，它就会选择一个最久没有被访问的内存页进行淘汰。
> 当然，淘汰前会把这个内存页的数据保存起来，因为下次 CPU 访问这个被淘汰的内存页时一样会发生缺页中断请求，那时操作系统还要去恢复数据。

通过虚拟内存的机制，操作系统并不需要一上来就把整个软件装进内存中，而是**通过缺页中断按需加载**对应的程序代码片段。内存不够用的时候，就把最久没有用过的内存页淘汰掉，腾出物理内存。

反正内存地址空间是虚拟的，操作系统可以一上来就给要运行的软件分配超级大的内存。软件如果不用某个内存页，什么都不发生。软件一旦用了某个内存页，通过缺页中断，操作系统就分配真正的物理内存给它。

通过引入虚拟内存及其缺页机制，CPU 很好地解决了操作系统和软件的配合关系。

虚拟地址并不是全局的，而是**每个进程有一个自己独立的虚拟地址空间**。

在保护模式下，每个软件“感觉”自己在独占整个计算机的资源。独立的虚拟地址空间很好地伪装了这一点：看起来我独自在享用所有内存资源。在实模式下的浮动地址的问题也解决了，软件可以假设自己代码加载的绝对地址是什么，不需要在加载的时候重新调整 CPU 指令操作的地址。

内存是进程运行的基础资源，保持进程基础资源的独立性，是软件治理的最基础的要求。这也是保护模式之所以叫“保护”模式的原因。

### 对架构思维的启示

虚拟内存本质上要解决这样两个核心需求：
1. 软件越来越大，我们需要考虑在外置存储上执行指令，而不是完整加载到内存中。但是外置存储一方面它的数据 CPU 并不知道怎么读；另一方面就算知道怎么读，也不知道它的数据格式是什么样的，这依赖文件系统的设计。让 CPU 理解外置存储的实现细节？这并不是一个好的设计。
2. 要同时运行的软件越来越多，计算机内存的供给与软件运行的内存需求相比，捉襟见肘。怎么才能把有限的内存的使用效率最大化？一个很容易想到的思路是把不经常使用的内存数据交换到外置存储。但是问题仍然是，CPU 并不了解外置存储的实现细节，怎么才能把内存按需交换出去？

通过**把虚拟内存地址分页**，引入**缺页中断**，我们非常巧妙地解决了这个问题。
缺页中断很像是 CPU 留给操作系统的回调函数，通过它对变化点实现了很好的开放性设计。

## 08操作系统内核与编程接口

软件如何利用它所依赖的基础架构？

- 首先是冯·诺依曼计算机体系，它由 “中央处理器 + 存储 + 一系列的输入输出设备” 构成。这一层，提供编程接口的是 CPU，编程接口是 CPU 指令。
- 其次是编程语言。编程语言面向人类，CPU 指令面向机器，编译器负责将编程语言的程序，翻译成机器能够理解的 CPU 指令序列。编程语言的自然演化越来越脱离 CPU 所限制的条条框框，大部分语言都演化出很多基础的算法库。
- 最后是操作系统。软件怎样才能使用操作系统的能力呢？大部分情况下，操作系统的能力通过**软中断**向软件开放，为此还专门引入了一个术语叫 “系统调用（syscall）”。

### 系统调用

中断的设计初衷是 CPU 响应硬件设备事件的一个机制。当某个输入输出设备发生了一件需要 CPU 来处理的事情，它就会触发一个中断；但是 CPU 也提供了指令允许软件触发一个中断，我们把它叫软中断。

系统调用所基于的软中断，它很像一次间接的“函数调用”，但是又颇有不同。在实模式下，这种区别并不强烈。但是在保护模式下，这种差异会十分明显。

根据与应用的关系，我们可以把操作系统分为内核与外围。所谓**操作系统内核**，其实就是指那些会向应用程序提供系统服务的子系统的集合，它们管理着计算机的所有硬件资源，也管理着所有运行中的应用软件（进程）。

操作系统内核的**执行权限等级**，和我们常规的软件进程不同。像 Intel CPU 通常把代码执行权限分为 Ring 0-3 四个等级。

我们的应用程序运行在 Ring 3（我们通常叫用户态），而操作系统内核运行在 Ring 0（我们通常叫内核态）。**所以一次中断调用，不只是“函数调用”，更重要的是改变了执行权限，从用户态跃迁到了内核态。**

操作系统与我们编写的软件并不同属一个进程，两边的内存地址空间都是独立的。我们系统调用请求是过去了，但是我们传给操作系统的内存地址，对它真的有意义吗？

答案在于，从虚拟内存机制的视角，**操作系统内核和所有进程都在同一个地址空间**，也就是，操作系统内核的内存是所有进程共享的。示意如下：

![所有进程共享操作系统内核](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/LoHJG4mLiCqZKi*fv21IWW8hu0M6*VZkyj.wUAMmvp0!/b/dCEBAAAAAAAA&bo=gAdiAwAAAAARF8Y!&rf=viewer_4)

操作系统内核的代码和数据，不只为所有进程所共享，而且**在所有进程中拥有相同的地址**。这样无论哪个进程请求过来，对内核来说看起来都是一次本进程内的请求。

内存页可以设置 “可读、可写、可执行” 三个标记位。操作系统内核虽然和用户进程同属一个地址空间，但是被设置为“不可读、不可写、不可执行”。虽然这段地址空间是有内容的，但是对于用户来说是个黑洞。

### 操作系统的编程接口

最原始的调用方式是用软中断指令。在汇编语言里通常是：
```
int < 中断号 > ;   // 对每个操作系统来说中断号是固定的，比如 Linux 是 0x80
```
int 是 interrupt 的缩写。

大部分高级语言都实现了操作系统编程接口的封装。

前面我们说，操作系统（内核）有六大子系统：存储管理、输入设备管理、输出设备管理、进程管理、网络管理、安全管理。除了安全管理是一个“润物细无声”的能力外，其他子系统都会有所包装。

我们以 C 语言和 Go 语言为例给一个简表，方便大家索引：

![Go和C对操作系统内核的编程接口的封装](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/.xm0f8Wi3FXltM1feg7Mh8KkO0*IbBwtmMSpVRUrCvo!/b/dJgAAAAAAAAA&bo=ZAKCAwAAAAARB9c!&rf=viewer_4)

### 动态库

从操作系统的角度来说，它仅仅提供最原始的系统调用是不够的，有很多业务逻辑的封装，在用户态来做更合适。但是，它也无法去穷举所有的编程语言，然后开发各种语言的基础库。那怎么办？

使用动态库。几乎所有主流操作系统都有自己的动态库设计，包括：
- Windows 的 dll（Dynamic Link Library）；
- Linux/Android 的 so（shared object）；
- Mac/iOS 的 dylib（Mach-O Dynamic Library）。

动态库本质上是实现了一个语言无关的代码复用机制。它是**二进制级别的复用**，而不是代码级别的。这大大降低了编程语言标准库的工作量。

动态库的原理其实很简单，核心考虑两个东西：
1. 浮动地址。动态库本质上是在一个进程地址空间中动态加载程序片段，这个程序片段的地址显然没法在编译阶段确定，要在加载动态库的过程中固定住浮动地址。
2. 导出函数表。动态库需要记录有哪些函数被导出（export），这样用户就可以通过函数的名字来取得对应的函数地址。

编程语言标准库的实现，多了一个选择：直接调用动态库的函数并进行适度的语义包装。大部分语言会选择这条路，而不是直接用系统调用。

### 操作系统与编程语言

编程语言和操作系统是两个非常独立的演化方向，却又彼此交融，它们有点像是某种“孪生关系”。虽然操作系统的诞生离不开编程语言，但是操作系统和 CPU 一样，是编程语言背后所依赖的基础设施。

和这个话题相关的，有这么一些有趣的问题：
- 先有编程语言，还是先有操作系统；
- 编程语言怎么做到自举的（比如用 C 语言来实现 C 语言编译器）；
- 操作系统开发的环境是什么样的，能够做到操作系统自身迭代本操作系统（自举）么？

#### 先有编程语言，还是先有操作系统？

这个问题的答案比较简单——先有编程语言。

之所以有这个疑问，是因为两点：
1. 大部分人习惯认为运行软件是操作系统的责任。但实际上软件跑起来是很容易的，看 BIOS 程序把控制权交给哪个软件。
2. 大部分常见的应用程序都直接或间接依赖操作系统的系统调用。这样来看，编程语言编译出来的程序是无法脱离操作系统而存在的。但是实际上常见的系统级语言（比如 C 语言）都是可以编写出不依赖任何内核的程序的。

#### 编程语言怎么做到自举的？

从鸡生蛋的角度，编译器的进化史应该是这样的：先用机器码直接写第一个汇编语言的编译器，然后汇编语言编译器编出第一个 C 语言编译器。有了 C 语言编译器后，可以反过来用 C 语言重写汇编语言编译器和 C 语言编译器，做更多的功能增强。

这个过程理论上每出现一种新 CPU 指令集、新操作系统，就需要重新来一遍。但是人是聪明的。所以**交叉编译**这样的东西产生了。所谓交叉编译就是在一种 “CPU + 操作系统” 架构下，生成另一种 “CPU + 操作系统” 架构下的软件。这就避免了需要把整个编译器进化史重新演绎一遍。

#### 操作系统能够自举么？

当然可以。通常一门新的操作系统开发之初，会用上面提到的交叉编译技术先干出来，然后等到新操作系统稳定到一定程度后再实现自举，也就是用本操作系统自己来做操作系统的后续迭代开发。

### 小结

这一节我们介绍了基础架构——中央处理器（CPU）、编程语言、操作系统，这三者对应用软件开放的编程接口。总结来看就是下面这样一幅图：

![基础架构开放给软件开发的编程接口](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/l7NCqE402I2zVJWfWxbWjHLMB3QGHPq0HSKmoBo6aG4!/b/dFEAAAAAAAAA&bo=xQU4BAAAAAARB8w!&rf=viewer_4)

其中，我们着重介绍的是操作系统的系统调用背后的实现机理。通过系统调用这个机制，我们很好地实现了操作系统和应用软件的隔离性和安全性，同时仍然保证了极好的执行性能。

## 09外存管理与文件系统

### 外存的分类

随着科技的发展，新的外置存储设备不断涌现，它们有着更低的单位能耗（存储量/每日能源消耗成本）、更低的单位存储成本（存储量/可存储的时间/设备价格）、更高的访问性能。

不管这些存储设备的原理怎么变，它们的功能是不变的。对操作系统来说，管理它们的方式非常一致。

按照这些外置存储设备的功能特性不同，可以分为三类：
- 顺序读写型。如：磁带。
- 随机只读型（单次完整写入，多次读取）。如：光盘（含可擦写光盘）。
- 随机读写型。如：软盘、硬盘、U 盘、SSD 等。

### 外存的数据格式

如何让很多软件进程同时使用外存设备，而不会混乱呢？

直接基于物理的存储地址进行读写，肯定行不通。你不会记得上次的数据写到哪里去了。

和内存管理不同，我们希望写到外部存储中的数据是“**自描述**”的某种数据格式，可以随时查看之前写了哪些内容、都是什么时候写的。
这就是**文件系统**的来源。

#### 文件系统

文件系统把存储设备中的数据组织成为了一棵树。节点可以是目录（也叫“文件夹”），也可以是文件。
每个节点，无论是目录还是文件，都有自己的名字、创建时间、最后编辑时间、最后访问时间等信息。有些文件系统还会提供最近一段时间的操作日志。

尽管几乎所有文件系统的**接口**是非常一致的，但文件系统的**实现**却有很多。

对于随机只读型的外置存储（如光盘），常见的文件系统有 ISO-9660, UDF, Joliet 等。它的数据格式偏向“读优化”，数据非常紧凑，不必支持分块。

对于随机读写型的存储（如硬盘），常见的文件系统有如下这些：

![随机读写型外存的常见文件系统](http://m.qpic.cn/psb?/V11Tp57c2B9kPO/g61meJ4fiCxPHCzyAbm2b2IxEuZkUB8OoySt9AiQmPk!/b/dBIAAAAAAAAA&bo=KQVEAgAAAAARB1o!&rf=viewer_4)

文件系统格式的设计，和架构关联性不大，更多的是数据结构与算法的问题。

文件系统的设计思路基本相似。大部分现代文件系统都基于日志（journal）来改善文件系统的防灾难能力（比如突然断电），基于 B 树或 B+ 树组织元数据。

古老的 DOS 引入的 FAT 文件系统（典型代表为 FAT32）是个例外，它直接把目录当作一个特殊的文件，里面依次列出了这个目录里的所有子节点的元信息。
这个结构虽然简单，但是如果目录树深、目录里的子节点数量多，都会大幅降低文件系统的性能。

#### 对外存的处理

对于随机读写型的存储设备，操作系统往往还支持对其进行分区，尤其是在这个存储设备的容量非常大的情况下。

1. 拿到一块存储设备，第一步往往是对其进行分区（当然也可以省略这一步，把整个设备看做一个分区）。**分区**本质上只是把一个存储设备模拟成多个存储设备来使用而已。
2. 第二步是对每个分区进行格式化。所谓**格式化**就是给这个分区生成文件系统的初始状态。格式化最重要的是**标记分区的文件系统格式**（用来告诉别人这个分区是数据是怎么组织的），并且生成文件系统的根目录。
3. 第三步是把该分区**挂载**（mount）到操作系统管理的文件系统名字空间中。完成挂载后，该分区的文件系统管理程序就工作起来了，我们可以对这个文件系统进行目录和文件的读取、创建、删除、修改等操作。


### 外存的使用接口

最简单的方式是使用操作系统提供的命令行工具。

最原始的方式是上一讲介绍的“系统调用”。不过大部分的编程语言对此都有相应的封装。

> 有意思的是，在早期，操作系统试图将所有的输入输出设备的接口都统一以 “文件” 来抽象它。
> 最典型的代表就是标准输入（stdin）和标准输出（stdout）这两个虚拟的文件，分别代表了键盘和显示器。在 UNIX 系里面有个 “一切皆文件” 的口号，便由此而来。
> 但事实证明 UNIX 错了。输入输出设备太多样化了，所谓的 “一切皆文件” 不过是象牙塔式的理想。就拿键盘和显示器来说，图形界面时代到来，所谓标准输入和标准输出就被推翻了，编程接口产生颠覆性的变化。

有了文件系统的使用接口，进程就可以互不影响地去使用这些外置存储设备。除非这些进程要操作的文件或目录的路径产生冲突（所谓路径，是指从根目录到该节点的访问序列。例如路径 /a/b/c 是从根目录访问子目录 a，再访问子子目录 b，最后访问节点 c），一般情况下它们并不需要感知到其他进程的存在。

路径冲突是可以避免的，只要我们对路径取名进行一些基础的名字空间约定，但有时候也会故意利用这种路径的冲突，来实现进程间的通讯。

操作系统提供了一些冲突检查的机制。例如 “检查文件是否存在，不存在就创建它”，这个语义在保证原子性的前提下，就可以用于做进程间的互斥。例如，我们希望一个软件不要运行多个进程实例，就可以基于这个机制来实现。

### 虚拟内存的支持

前面我们在 07 讲中提到，在物理内存不足的时候，操作系统会利用外存把一些很久没有使用的内存页的数据，保存到外存以进行淘汰。

在 UNIX 系的操作系统中，操作系统为此分配了一个磁盘分区叫 swap 分区，专门用于内存页的保存和恢复。在 Windows 操作系统中则通过一个具有隐藏属性的 .swp 文件来实现。

在缺页发生比较频繁时，内存页的数据经常性发生保存和恢复，这会发生大量的磁盘 IO 操作，非常占用 CPU 时间，这时候我们通常能够明显感觉到计算机变得很慢。

在计算机变慢，并且计算机的硬盘灯不停闪烁的时候，我们基本可以确定是物理内存严重不足，不能满足运行中的软件的内存需要。

### 小结

整体来说，外存管理从架构角度来说比较简单，复杂性主要集中在外存数据格式，也就是文件系统的设计上。

如果你希望进一步研究某个文件系统的具体实现细节，我这里推荐一个[由七牛云开源的 BPL 语言](https://github.com/qiniu/bpl)（Binary Processing Language，二进制处理语言）。
顾名思义，BPL 语言主要用于分析二进制数据格式。应用场景包括：文件格式分析（含磁盘分区格式，因为一个磁盘分区可以把它理解为一个大文件）、网络协议分析。

后面介绍文本处理相关的章节，还会专门拿出 BPL 语言进行讨论。

## 10输入和输出设备

| 时期 | 输入设备 | 输出设备 |
|-|-|-|
| 早期 | 打孔卡 | 打印机 |
| 字符界面时期 | 键盘 | 显示器 |
| 图形界面时期 | 键盘+鼠标 | 显示器+音箱 |
| 移动时期 | 触摸屏+麦克风 | 触摸屏+内置扬声器 |
| IoT 萌芽时期 | 麦克风 | 内置扬声器 |
| 拟真交互（可能的未来） | 摄像头+麦克风 | VR |

### 输入设备

#### 键盘

大部分情况下，键盘输入的事件会先发给焦点窗口，焦点窗口不处理则发给其父窗口，按此传递，直到有人处理了该按键事件，或者直到顶层窗口。

键盘从功能上来说，有两个不同的能力：**其一是输入文本，其二是触发命令。**

从输入文本的角度来说，要有一个输入光标（在 Windows 里面叫 Caret）来指示输入的目的窗口。目的窗口也是焦点窗口。
这个交互的呈现方式非常稳定，从 DOS 到 Windows/Mac，到 iOS/Android 都是如此。

但是从触发命令的角度来说，命令的响应并不一定是在焦点窗口，甚至不一定在活跃窗口。
比如 Windows 下就有热键（HotKey）的概念，能够让非活跃窗口（Inactive Window）也获得响应键盘命令的机会。
移动时代的热键被设计为系统功能保留了下来。

#### 鼠标

#### 麦克风

交互方式不管怎么变化，其核心需要实现的都是这样的两大能力：输入文本和触发命令，这一点是不变的。

语音交互在 IoT 领域还停留在触发命令为主，而且这一件事情也还有许多关卡需要突破。

#### 摄像头

技术所限，还在萌芽阶段。
微软的 Kinect 是一个经典案例。

### 输出设备

#### 显示器

在逻辑上，通过引入**窗口**（window，也有叫 view），操作系统把显示器屏幕这个有限的设备资源，分配给了多个软件。
和 PC 不同的是，移动设备由于屏幕过小，所以操作系统选择了让软件的顶层窗口全屏占据整个屏幕。这让显示器屏幕的管理变得更为简单。

除了窗口系统，显示设备管理的另一大挑战是**绘制子系统**。
窗口里面的内容是什么、呈现成什么样子，完全是软件来决定的，这就意味着软件需要绘制能力。

绘制能力牵涉面非常之广，在操作系统里面，往往有一个独立的子系统（通常叫 GDI）与之对应。这里简单罗列一下 GDI 子系统会涉及哪些东西：
- 2D 图形相关。包含 Path(路径)、Brush(画刷)、Pen(画笔) 等概念。
- 3D 图形相关。包含 Model(模型)、Material(材质)、Lighting(光照) 等概念。
- 文本相关。包含 Font(字体) 等概念。而字体又分点阵字体和 TrueType 字体。TrueType 字体的优势是可以自由缩放。今天我们见到的大部分字体都是 TrueType 字体。
- 图像处理相关。包含 Bitmap(位图) 对象及常见图像格式的编解码器 (Encoder/Decoder)。

**窗口系统**结合输入设备对应的**事件管理系统**、**绘制 (GDI) 系统**，我们就可以随心所欲地实现各类用户体验非常友好的视窗软件了。

为了进一步简化开发过程，操作系统往往还提供了一些通用的界面元素，即控件 (Control)。
不同操作系统提供的基础控件大同小异，不过一些处理细节上的差异往往会成为跨平台开发的坑。

#### 音箱

#### 打印机

软件使用打印机的过程基本上是互斥的。互斥的单位是文档。
为了避免软件之间出现长时间的相互等待，操作系统往往在打印机的管理程序中引入很大的打印缓冲。
软件操作打印机的时候，把文档打印到打印缓冲中就算完成打印。这样就避免了大多数情况下软件相互等待的问题。

### 小结

尽管对 CPU 而言，所有外部设备有着相同的抽象，但这些设备的业务逻辑却如此不同，并不能统一抽象它们。正是因为有了操作系统这样的基础软件，这些设备业务逻辑的复杂性才从我们的软件开发过程中解放出来。

人机交互演化的核心变化是输入设备的变化。我们看到，输入手段的变化是非常剧烈的，且每一次演变都是颠覆性的变化。

事实上**输入意图的理解越来越难了**，因为交互在朝着自然（Nature）和智能（Intelligence）的方向发展。我们不可能让每一个软件都自己去做输入意图的理解（今天的现状是每个软件自己做），**在未来，必然将由操作系统来实现智能交互的基础架构**。
